{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# 设置你的 Hugging Face API Token\n",
    "hf_token = \"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\"\n",
    "\n",
    "# 登录 Hugging Face，设置 API Token\n",
    "login(hf_token)\n",
    "\n",
    "print(\"Successfully logged in to Hugging Face!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune model Finance chat with Fiqa dataset\n",
    "\n",
    "* Model information:\n",
    "    - Model name: [AdaptLLM/finance-chat](https://huggingface.co/AdaptLLM/finance-chat)\n",
    "    - Description: the domain-specific chat model developed from LLaMA-2-Chat-7B, using the method in our ICLR 2024 paper Adapting Large Language Models via Reading Comprehension.\n",
    "    - List dataset used to train:\n",
    "        - [Open-Orca/OpenOrca](https://huggingface.co/datasets/Open-Orca/OpenOrca)\n",
    "        - [GAIR/lima](https://huggingface.co/datasets/GAIR/lima)\n",
    "        - [WizardLM/WizardLM_evol_instruct_V2_196k](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)\n",
    "* Dataset information:\n",
    "    - Dataset name: [FinGPT/fingpt-fiqa_qa](https://huggingface.co/datasets/FinGPT/fingpt-fiqa_qa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install packages, setup global settings\n",
    "### 1.1 Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers peft accelerate trl\n",
    "!pip install datasets==2.16.1\n",
    "!pip install evaluate rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Setup Global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "os.environ[\"HF_TOKEN\"] = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "os.environ[\"WANDB_API_KEY\"] = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "\n",
    "# Indicate availability CUDA devices to help Trainer can recognize and use then in training process\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = \"FinGPT/fingpt-fiqa_qa\"\n",
    "\n",
    "# load piece data of datasets\n",
    "def get_dataset(from_pc=0, to_pc=10):\n",
    "    dataset_dict = load_dataset(DATASET_NAME, split=\"train[10%:20%]\")\n",
    "    \n",
    "    # rename columns of dataset to fix with format: system_prompt, question, response\n",
    "    dataset_dict = dataset_dict.rename_column(\"instruction\", \"system_prompt\")\n",
    "    dataset_dict = dataset_dict.rename_column(\"input\", \"question\")\n",
    "    dataset_dict = dataset_dict.rename_column(\"output\", \"response\")\n",
    "    \n",
    "    dataset = dataset_dict.train_test_split(test_size=0.1)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_instruction(sample):\n",
    "#     return f\"\"\"### System prompt:\n",
    "# {sample['system_prompt']}\n",
    "\n",
    "# ### Question:\n",
    "# {sample[\"question\"]}\n",
    "\n",
    "# ### Response:\n",
    "# {sample[\"response\"]}\n",
    "# \"\"\"\n",
    "\n",
    "def format_instruction(sample):\n",
    "    return f\"\"\"<s>[INST] <<SYS>>{sample[\"system_prompt\"]}<</SYS>>\\n\\nQuestion: {sample[\"question\"]}\\n\\nResponse: {sample[\"response\"]} [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a piece of data because it is big dataset\n",
    "training_dataset = get_dataset(0, 11)\n",
    "print(training_dataset)\n",
    "\n",
    "# test format instruction\n",
    "example = training_dataset[\"train\"][5]\n",
    "print(format_instruction(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "\n",
    "MODEL_NAME = \"AdaptLLM/finance-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load model in qantization mode 4 big\n",
    "    - https://huggingface.co/docs/accelerate/en/usage_guides/quantization\n",
    "    - https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "    \"\"\"\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        quantization_config=quant_config,\n",
    "        device_map = \"auto\",\n",
    "        token=True\n",
    "    )\n",
    "    \n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        token=True,\n",
    "        add_eos_token=True,\n",
    "        add_bos_token=True,\n",
    "        # WARN: Ignore the warning of SFTTrainer for use padding_side=\"right\", using padding side right will cause the model can't generate eos token\n",
    "        padding_side=\"left\",\n",
    "    )\n",
    "    \n",
    "    # https://clay-atlas.com/us/blog/2024/01/01/mistral-sft-trainer-cannot-generate-eos-token/\n",
    "    tokenizer.pad_token = tokenizer.unk_token\n",
    "    \n",
    "    \n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "# Clean cache before loading model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load model and tokenizer\n",
    "model, tokenizer = load_model()\n",
    "\n",
    "# Check number of trainable parameters\n",
    "print(print_number_of_trainable_model_parameters(model))\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Example to chat with the finance-chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Input Texts:\n",
    "{Recent indicators suggest that economic activity has continued to expand at a solid pace. Job gains have slowed, and the unemployment rate has moved up but remains low. Inflation has made further progress toward the Committee's 2 percent objective but remains somewhat elevated.\n",
    "The Committee seeks to achieve maximum employment and inflation at the rate of 2 percent over the longer run. The Committee has gained greater confidence that inflation is moving sustainably toward 2 percent, and judges that the risks to achieving its employment and inflation goals are roughly in balance. The economic outlook is uncertain, and the Committee is attentive to the risks to both sides of its dual mandate.\n",
    "In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage‑backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
    "In assessing the appropriate stance of monetary policy, the Committee will continue to monitor the implications of incoming information for the economic outlook. The Committee would be prepared to adjust the stance of monetary policy as appropriate if risks emerge that could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
    "Based on the provided text, I would classify the overall sentiment and tone as neutral to cautiously optimistic, with an emphasis on ongoing progress and a balanced risk outlook.}\n",
    "\n",
    "Given a list of cleaned text data, conduct a sentiment analysis to evaluate the emotional tone of each text (e.g., positive, neutral, negative). Provide a confidence score for each sentiment classification, as well as a high-level explanation that justifies the analysis. Additionally, assess the potential implications these sentiments may have on the perception of {topic/subject}. Your response should be structured only as follows:\n",
    "\n",
    "\t1.\tSentiment Polarity (Positive, Neutral, Negative)\n",
    "\t2.\tConfidence Score (0 to 9 scale)\n",
    "\"\"\"\n",
    "\n",
    "# Apply the prompt template and system prompt of LLaMA-2-Chat demo for chat models (NOTE: NO prompt template is required for base models!)\n",
    "our_system_prompt = \"\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\" # Please do NOT change this\n",
    "prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n",
    "\n",
    "# # NOTE:\n",
    "# # If you want to apply your own system prompt, please integrate it into the instruction part following our system prompt like this:\n",
    "# your_system_prompt = \"Please, check if the answer can be inferred from the pieces of context provided.\"\n",
    "# prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{your_system_prompt}\\n{user_input} [/INST]\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model.device)\n",
    "outputs = model.generate(input_ids=inputs, max_length=4096)[0]\n",
    "\n",
    "answer_start = int(inputs.shape[-1])\n",
    "pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n",
    "\n",
    "print(f'### User Input:\\n{user_input}\\n\\n### Assistant Output:\\n{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = training_dataset[\"train\"][1]\n",
    "user_input = test[\"question\"]\n",
    "\n",
    "# Apply the prompt template and system prompt of LLaMA-2-Chat demo for chat models (NOTE: NO prompt template is required for base models!)\n",
    "our_system_prompt = test[\"system_prompt\"]\n",
    "prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model.device)\n",
    "outputs = model.generate(input_ids=inputs, max_length=4096)[0]\n",
    "\n",
    "answer_start = int(inputs.shape[-1])\n",
    "pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n",
    "\n",
    "print(f'### User Input:\\n{user_input}\\n\\n### Assistant Output:\\n{pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. LoRA configuration and Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Lora\n",
    "lora_config = LoraConfig(\n",
    "    # Lora attention dimension\n",
    "    r=64,\n",
    "    # Scaling process\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    # Prevent overfitting\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "LEARNING_RATE = 1e-5 # 2e-4\n",
    "WEIGHT_DECAY=0.001\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 4\n",
    "LOGGING_STEPS = 10\n",
    "MAX_SEQ_LEN = 2048\n",
    "MAX_STEPS = -1\n",
    "\n",
    "TRAINING_OUTPUT_DIR=f\"outputs/peft-financial-chatbot-trained-{str(int(time.time()))}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=TRAINING_OUTPUT_DIR,\n",
    "    \n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    max_steps=MAX_STEPS,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    \n",
    "    # max_grad_norm=0.3, # measure of the magnitude or steepness of the gradient of a loss function\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    \n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=BATCH_SIZE,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=LOGGING_STEPS,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    \n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    "    \n",
    "    train_dataset=training_dataset[\"train\"],\n",
    "    eval_dataset=training_dataset[\"test\"],\n",
    "    dataset_text_field=\"question\",\n",
    "    \n",
    "    max_seq_length=None,\n",
    "    formatting_func=format_instruction,\n",
    "#     packing=True\n",
    ")\n",
    "\n",
    "print(training_args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PEFT_MODEL_LOCAL_CHECKPOINT = \"./outputs/peft-training-checkpoint\"\n",
    "PEFT_MODEL_ADAPTER_ID = \"anhtranhong/finance-chat_fingpt-fiqa_qa_v2\"\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(PEFT_MODEL_LOCAL_CHECKPOINT)\n",
    "tokenizer.save_pretrained(PEFT_MODEL_LOCAL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Push to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFT_MODEL_ADAPTER_ID = \"anhtranhong/finance-chat_fingpt-fiqa_qa_v1.1_test\"\n",
    "trainer.model.push_to_hub(PEFT_MODEL_ADAPTER_ID)\n",
    "tokenizer.push_to_hub(PEFT_MODEL_ADAPTER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(model, PEFT_MODEL_ADAPTER_ID, is_trainable=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    PEFT_MODEL_ADAPTER_ID,\n",
    "    padding_side=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = training_dataset[\"train\"][1]\n",
    "\n",
    "# user_input = sample[\"question\"]\n",
    "\n",
    "# # our_system_prompt = \"\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\" # Please do NOT change this\n",
    "# our_system_prompt = sample[\"system_prompt\"]\n",
    "\n",
    "# prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n",
    "# user_input = \"\"\"\n",
    "# Input Texts:\n",
    "# {Recent indicators suggest that economic activity has continued to expand at a solid pace. Job gains have slowed, and the unemployment rate has moved up but remains low. Inflation has made further progress toward the Committee's 2 percent objective but remains somewhat elevated.\n",
    "# The Committee seeks to achieve maximum employment and inflation at the rate of 2 percent over the longer run. The Committee has gained greater confidence that inflation is moving sustainably toward 2 percent, and judges that the risks to achieving its employment and inflation goals are roughly in balance. The economic outlook is uncertain, and the Committee is attentive to the risks to both sides of its dual mandate.\n",
    "# In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage‑backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
    "# In assessing the appropriate stance of monetary policy, the Committee will continue to monitor the implications of incoming information for the economic outlook. The Committee would be prepared to adjust the stance of monetary policy as appropriate if risks emerge that could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
    "# Based on the provided text, I would classify the overall sentiment and tone as neutral to cautiously optimistic, with an emphasis on ongoing progress and a balanced risk outlook.}\n",
    "\n",
    "# Given a list of cleaned text data, conduct a sentiment analysis to evaluate the emotional tone of each text (e.g., positive, neutral, negative). Provide a confidence score for each sentiment classification, as well as a high-level explanation that justifies the analysis. Additionally, assess the potential implications these sentiments may have on the perception of {topic/subject}. Your response should be structured only as follows:\n",
    "\n",
    "# \t1.\tSentiment Polarity (Positive, Neutral, Negative)\n",
    "# \t2.\tConfidence Score (0 to 9 scale)\n",
    "# \"\"\"\n",
    "user_input = \"\"\"\n",
    "Input Texts:\n",
    "Recent indicators suggest that economic activity has continued to expand at a solid pace. Job gains have slowed, and the unemployment rate has moved up but remains low. Inflation has made further progress toward the Committee's 2 percent objective but remains somewhat elevated.\n",
    "The Committee seeks to achieve maximum employment and inflation at the rate of 2 percent over the longer run. The Committee has gained greater confidence that inflation is moving sustainably toward 2 percent, and judges that the risks to achieving its employment and inflation goals are roughly in balance. The economic outlook is uncertain, and the Committee is attentive to the risks to both sides of its dual mandate.\n",
    "In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage‑backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
    "In assessing the appropriate stance of monetary policy, the Committee will continue to monitor the implications of incoming information for the economic outlook. The Committee would be prepared to adjust the stance of monetary policy as appropriate if risks emerge that could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
    "\n",
    "Based on the text above, provide a sentimental analysis score from 0-10. 0 means absolutely negative and 10 means very positive.\"\"\"\n",
    "\n",
    "\n",
    "# Apply the prompt template and system prompt of LLaMA-2-Chat demo for chat models (NOTE: NO prompt template is required for base models!)\n",
    "our_system_prompt = \"\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\" # Please do NOT change this\n",
    "prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{user_input} [/INST]\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(model.device)\n",
    "outputs = peft_model.generate(\n",
    "    input_ids=inputs,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.2,\n",
    "    num_return_sequences=1,\n",
    ")[0]\n",
    "\n",
    "answer_start = int(inputs.shape[-1])\n",
    "pred = tokenizer.decode(outputs[answer_start:], skip_special_tokens=True)\n",
    "\n",
    "print(f\"### User Input:\\n{user_input}\\n\\n### Assistant Output:\\n{pred}\\n\\n\")\n",
    "\n",
    "# print(f\"### Response from dataset:\\n{sample['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Input Texts:\n",
    "{Recent indicators suggest that economic activity has continued to expand at a solid pace. Job gains have slowed, and the unemployment rate has moved up but remains low. Inflation has made further progress toward the Committee's 2 percent objective but remains somewhat elevated.\n",
    "The Committee seeks to achieve maximum employment and inflation at the rate of 2 percent over the longer run. The Committee has gained greater confidence that inflation is moving sustainably toward 2 percent, and judges that the risks to achieving its employment and inflation goals are roughly in balance. The economic outlook is uncertain, and the Committee is attentive to the risks to both sides of its dual mandate.\n",
    "In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage‑backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
    "In assessing the appropriate stance of monetary policy, the Committee will continue to monitor the implications of incoming information for the economic outlook. The Committee would be prepared to adjust the stance of monetary policy as appropriate if risks emerge that could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
    "Based on the provided text, I would classify the overall sentiment and tone as neutral to cautiously optimistic, with an emphasis on ongoing progress and a balanced risk outlook.}\n",
    "\n",
    "Given a list of cleaned text data, conduct a sentiment analysis to evaluate the emotional tone of each text (e.g., positive, neutral, negative). Provide a confidence score for each sentiment classification, as well as a high-level explanation that justifies the analysis. Additionally, assess the potential implications these sentiments may have on the perception of {topic/subject}. Your response should be structured only as follows:\n",
    "\n",
    "\t1.\tSentiment Polarity (Positive, Neutral, Negative)\n",
    "\t2.\tConfidence Score (0 to 9 scale)\n",
    "\"\"\"\n",
    "\n",
    "# Apply the prompt template and system prompt of LLaMA-2-Chat demo for chat models (NOTE: NO prompt template is required for base models!)\n",
    "our_system_prompt = \"\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\n\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\\n\" # Please do NOT change this\n",
    "prompt = f\"<s>[INST] <<SYS>>{our_system_prompt}<</SYS>>\\n\\n{user_input} [/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Input Texts:\n",
    "{Recent indicators suggest that economic activity has continued to expand at a solid pace. Job gains have slowed, and the unemployment rate has moved up but remains low. Inflation has made further progress toward the Committee's 2 percent objective but remains somewhat elevated.\n",
    "The Committee seeks to achieve maximum employment and inflation at the rate of 2 percent over the longer run. The Committee has gained greater confidence that inflation is moving sustainably toward 2 percent, and judges that the risks to achieving its employment and inflation goals are roughly in balance. The economic outlook is uncertain, and the Committee is attentive to the risks to both sides of its dual mandate.\n",
    "In light of the progress on inflation and the balance of risks, the Committee decided to lower the target range for the federal funds rate by 1/2 percentage point to 4-3/4 to 5 percent. In considering additional adjustments to the target range for the federal funds rate, the Committee will carefully assess incoming data, the evolving outlook, and the balance of risks. The Committee will continue reducing its holdings of Treasury securities and agency debt and agency mortgage‑backed securities. The Committee is strongly committed to supporting maximum employment and returning inflation to its 2 percent objective.\n",
    "In assessing the appropriate stance of monetary policy, the Committee will continue to monitor the implications of incoming information for the economic outlook. The Committee would be prepared to adjust the stance of monetary policy as appropriate if risks emerge that could impede the attainment of the Committee's goals. The Committee's assessments will take into account a wide range of information, including readings on labor market conditions, inflation pressures and inflation expectations, and financial and international developments.\n",
    "Based on the provided text, I would classify the overall sentiment and tone as neutral to cautiously optimistic, with an emphasis on ongoing progress and a balanced risk outlook.}\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
